{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from transformers import AutoTokenizer, LongformerTokenizer, AutoModelForCausalLM\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "from konlpy.tag import Okt\n",
    "from hanspell import spell_checker\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_base = \"/home/aicontest/aicon_2025/data/original\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>full_text</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>카호올라웨섬</td>\n",
       "      <td>카호올라웨섬은 하와이 제도를 구성하는 8개의 화산섬 가운데 하나로 면적은 115.5...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>청색거성</td>\n",
       "      <td>천문학에서 청색거성(靑色巨星, )은 광도 분류에서 III형(거성) 또는 II형(밝은...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>엘자스-로트링겐 평의회 공화국</td>\n",
       "      <td>엘자스-로트링겐 평의회 공화국은 1차대전 말기 독일 혁명 와중에 엘자스-로트링겐에서...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>윌리엄 페니 브룩스</td>\n",
       "      <td>윌리엄 페니 브룩스(, 1809년 8월 13일 ~ 1895년 12월 11일)는 잉글...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>미그로</td>\n",
       "      <td>미그로 또는 미그로스(\"Migros\")는 스위스 최대 소매 회사이자, 최대 슈퍼마켓...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              title                                          full_text  \\\n",
       "0            카호올라웨섬  카호올라웨섬은 하와이 제도를 구성하는 8개의 화산섬 가운데 하나로 면적은 115.5...   \n",
       "1              청색거성  천문학에서 청색거성(靑色巨星, )은 광도 분류에서 III형(거성) 또는 II형(밝은...   \n",
       "2  엘자스-로트링겐 평의회 공화국  엘자스-로트링겐 평의회 공화국은 1차대전 말기 독일 혁명 와중에 엘자스-로트링겐에서...   \n",
       "3        윌리엄 페니 브룩스  윌리엄 페니 브룩스(, 1809년 8월 13일 ~ 1895년 12월 11일)는 잉글...   \n",
       "4               미그로  미그로 또는 미그로스(\"Migros\")는 스위스 최대 소매 회사이자, 최대 슈퍼마켓...   \n",
       "\n",
       "   generated  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(f\"{data_base}/train.csv\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "카호올라웨섬은 하와이 제도를 구성하는 8개의 화산섬 가운데 하나로 면적은 115.5km2, 높이는 452m이다. 하와이 제도에서 가장 작은 화산섬이자 무인도이며 길이는 18km, 너비는 10km이다. \n",
      " 마우이섬에서 남서쪽으로 약 11km 정도 떨어진 곳에 위치하며 라나이섬의 남동쪽에 위치한다. 고도가 낮고 북동쪽에서 불어오는 무역풍을 통해 산악 지대에서 내리는 비를 형성하지 못하기 때문에 건조한 기후를 띤다. 마우이섬 화산의 비그늘에 속해 있기 때문에 섬 전체 면적의 1/4 이상이 부식되어 있다. \n",
      " 1000년경부터 사람이 거주했으며 해안 지대에는 소규모 임시 어촌이 형성되었다. 섬 안에는 주민들이 돌로 만든 제단에서 종교 의식을 거행한 흔적들, 주민들이 암석이나 평평한 돌에 그림을 그린 흔적들이 남아 있다. 1778년부터 1800년대까지 이 지역을 지나 항해하던 사람들의 보고에 따르면 카호올라웨섬은 무인도였고 나무도 물도 없는 불모지였다고 한다. \n",
      " 1830년대에는 하와이 왕국의 카메하메하 3세 국왕에 의해 남자 죄수들의 유형지로 사용되었지만 1853년에 폐지되었다. 1858년에는 하와이 정부가 목장 사업가들에게 카호올라웨섬을 양도했지만 가뭄과 과도한 방목으로 인해 땅이 말라갔다. 또한 강한 무역풍으로 인해 표토의 대부분이 날아가면서 붉은 경반층만 남게 되었다. \n",
      " 1910년부터 1918년까지 하와이 준주가 섬의 원래 모습을 복원하기 위해 이 섬을 천연보호구역으로 지정했지만 큰 성과를 거두지 못했다. \n",
      " 1941년 12월 7일에 일어난 일본 제국 해군의 진주만 공격을 계기로 카호올라웨섬은 태평양 전쟁에 참전한 미국 병사들의 훈련소로 사용되었다. 1981년 3월 18일에는 미국 국립사적지에 등재되었다.\n"
     ]
    }
   ],
   "source": [
    "cheaker = train_df[\"full_text\"]\n",
    "print(cheaker[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_0 = [i for _, i in train_df.iterrows() if i['generated'] == 0]\n",
    "label_1 = [i for _, i in train_df.iterrows() if i['generated'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 개수 : 97172\n",
      "평균 text 길이 : 2323.227822829622\n",
      "가장 길이가 긴거 : 98549\n",
      "가장 길이가 짧은거 : 393\n"
     ]
    }
   ],
   "source": [
    "print(f\"데이터 개수 : {len(train_df)}\")\n",
    "avg_text = sum([len(i) for i in train_df[\"full_text\"]])/len(train_df)\n",
    "print(f\"평균 text 길이 : {avg_text}\")\n",
    "max_length = max([len(i) for i in train_df[\"full_text\"]])\n",
    "min_length = min([len(i) for i in train_df[\"full_text\"]])\n",
    "print(f\"가장 길이가 긴거 : {max_length}\")\n",
    "print(f\"가장 길이가 짧은거 : {min_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('카호올라웨섬', 1),\n",
       " ('청색거성', 1),\n",
       " ('엘자스-로트링겐 평의회 공화국', 1),\n",
       " ('윌리엄 페니 브룩스', 1),\n",
       " ('미그로', 1)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = Counter(train_df[\"title\"]).most_common(5)\n",
    "count\n",
    "\n",
    "# 각각 하나의 title 을 가지고 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "클래스 비율 : 0.08227678755196971\n",
      "가중치 : 12.154096310193871\n"
     ]
    }
   ],
   "source": [
    "print(f\"클래스 비율 : {sum(train_df['generated'])/len(train_df)}\")\n",
    "print(f\"가중치 : {len(train_df)/sum(train_df['generated'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97172/97172 [04:57<00:00, 326.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "잘린다고 예상되는 샘플 수: 29704 / 전체 97172개 중 30.57%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = LongformerTokenizer.from_pretrained('allenai/longformer-base-4096')\n",
    "\n",
    "cut = 0\n",
    "for _, row in tqdm(train_df.iterrows(), total=len(train_df)):\n",
    "    text = row['title'] + \" \" + row['full_text']\n",
    "    output = tokenizer(\n",
    "        text,\n",
    "        truncation=False,            # ✅ 자르지 않음\n",
    "        padding=False,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    if output['input_ids'].shape[1] > 4096:\n",
    "        cut += 1\n",
    "\n",
    "print(f\"잘린다고 예상되는 샘플 수: {cut} / 전체 {len(train_df)}개 중 {cut / len(train_df) * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>title</th>\n",
       "      <th>paragraph_index</th>\n",
       "      <th>paragraph_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_0000</td>\n",
       "      <td>공중 도덕의 의의와 필요성</td>\n",
       "      <td>0</td>\n",
       "      <td>도덕이란 원래 개인의 자각에서 출발해 자기 의지로써 행동하는 일이다. 그러므로 도덕...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_0001</td>\n",
       "      <td>공중 도덕의 의의와 필요성</td>\n",
       "      <td>1</td>\n",
       "      <td>도덕은 단순히 개인의 문제나 사회의 문제로 한정될 수 없다. 개인적인 측면과 사회적...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_0002</td>\n",
       "      <td>공중 도덕의 의의와 필요성</td>\n",
       "      <td>2</td>\n",
       "      <td>여기에 이른바 공중도덕은 실천적, 사회적 도덕의 한 부문이다. 즉, 공중 도덕이라 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_0003</td>\n",
       "      <td>공중 도덕의 의의와 필요성</td>\n",
       "      <td>3</td>\n",
       "      <td>우리가 공동 생활을 하는 데 있어서 공중 도덕이 필요함은 위에서 말한 것처럼 알 수...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_0004</td>\n",
       "      <td>풍습과 그 개선</td>\n",
       "      <td>0</td>\n",
       "      <td>인간 사회에서는 다 함께 지켜야 할 어떤 기준이 있어 이를 따르면 옳다고 하고 따르...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID           title  paragraph_index  \\\n",
       "0  TEST_0000  공중 도덕의 의의와 필요성                0   \n",
       "1  TEST_0001  공중 도덕의 의의와 필요성                1   \n",
       "2  TEST_0002  공중 도덕의 의의와 필요성                2   \n",
       "3  TEST_0003  공중 도덕의 의의와 필요성                3   \n",
       "4  TEST_0004        풍습과 그 개선                0   \n",
       "\n",
       "                                      paragraph_text  \n",
       "0  도덕이란 원래 개인의 자각에서 출발해 자기 의지로써 행동하는 일이다. 그러므로 도덕...  \n",
       "1  도덕은 단순히 개인의 문제나 사회의 문제로 한정될 수 없다. 개인적인 측면과 사회적...  \n",
       "2  여기에 이른바 공중도덕은 실천적, 사회적 도덕의 한 부문이다. 즉, 공중 도덕이라 ...  \n",
       "3  우리가 공동 생활을 하는 데 있어서 공중 도덕이 필요함은 위에서 말한 것처럼 알 수...  \n",
       "4  인간 사회에서는 다 함께 지켜야 할 어떤 기준이 있어 이를 따르면 옳다고 하고 따르...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(f\"{data_base}/test.csv\")\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "도덕이란 원래 개인의 자각에서 출발해 자기 의지로써 행동하는 일이다. 그러므로 도덕은 어디까지나 정신의 문제이고, 각자의 마음씨에 달려있는 일이다. 여기에서 도덕의 문제는 철학적 이론으로 발전하였으며, 고상하고 심원한 이론 체계에 기울어지는 경향이 많았다. 이러한 경향으로 인해 도덕은 학식이 높은 특수한 사람만이 닦을 수 있는 것으로 여겨지며, 일반 사람은 도저히 지킬 수 없는 것처럼 오해받는 경우가 많았다. 그러나 도덕의 본질은 결코 이론에 있는 것이 아니라 실천에 있다. 이론이 필요하다면 그것은 오직 실천을 위한 도구로서만 의미를 가진다. 아무리 고상한 이론이라도 실천이 없다면 그 이론은 단순한 관념의 유희에 불과하다.\n"
     ]
    }
   ],
   "source": [
    "cheaker = test_df[\"paragraph_text\"]\n",
    "print(cheaker[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 개수 : 1962\n"
     ]
    }
   ],
   "source": [
    "print(f\"데이터 개수 : {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = Counter(test_df[\"title\"]).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "보이지 않는 재산 : 0\n",
      "과거의 세상에 살고 있는 너에게 : 0\n",
      "교육계의 미래를 위한 제언 : 0\n",
      "‘그럼에도 불구하고’ 지켜야 할 가치 : 0\n",
      "화이트칼라로봇의 등장과 메타버스에서 일하는시대 : 0\n",
      "메타버스 시대가 온다 : 0\n",
      "내가 만드는 모두의 권리 : 0\n",
      "책을 읽고 싶어요 : 0\n",
      "4차 산업혁명과 향후 한국교육의 방향 : 0\n",
      "교원평가제도와 성과급: 취지와 개선점 : 0\n",
      "인구감소시대 소멸위험 지자체의 생존전략 : 0\n",
      "과학기술 인재로 쌓아 올릴 한국의 실력 : 0\n",
      "코로나바이러스·중국·기후변화' 3C의 위기를 넘어서 : 0\n",
      "개헌, 더이상 미룰 수 없는 시대적 과제 : 0\n",
      "나누면 더 잘사는 국가균형발전, 더 이상 미룰 수 없는 미래다 : 0\n",
      "누가 태화관길을 없앴나 : 0\n",
      "국제기구가 평가한 우리나라 에너지부문 성적표 : 0\n",
      "대전환기의 분기점으로서 2021년의 국가전략 : 0\n",
      "청년이 살아야 대한민국이 산다 : 0\n",
      "0.10% : 0\n",
      "저작권! 내가 먼저 지켜야지 : 0\n",
      "답은 늘 규제가 아니라 시장이었다. 앞으로도 그럴 것이다. : 0\n",
      "탄소중립 선언과 미래세대를 위한 준비 : 0\n",
      "건강한 잎이 많은 사회와 우리 미래의 비례 공식 : 0\n",
      "나는 저작권 스타일 : 0\n",
      "글로벌 블록체인 정책 협의체 출범, '미래를 향한 용기 있는 진일보' : 0\n",
      "포스트 코로나19 세상에서는 새로운 인간성이 나타날 것이다 : 0\n",
      "과학기술로 실력과 품격을 : 0\n",
      "여가부가 필요 없는 성평등 대한민국을 꿈꾸며 : 0\n",
      "미래 청사진은 아이 울음소리 울려 퍼지는 대한민국에서 : 0\n",
      "이야기꾼과심술할아버지 : 0\n",
      "미래의 민주주의와 민주주의 미래 : 0\n",
      "감염병 확산 下의 아주 가까운 미래 : 0\n",
      "코로나 대응 정보기술 활용법 : 0\n",
      "코로나가 가르쳐 준 미래 생존법 '성찰과 공존' : 0\n",
      "COVID-19 시대, 우리나라 국가혁신체제 어떻게 변화할 것인가? : 0\n",
      "미래 정책시스템의 틀: 격변과학기술에 대한 신중한 경계 : 0\n",
      "탄소국경조정의 현황과 미래영향에 관한 소고 : 0\n",
      "포스트 코로나 시기를 위한 산업정책 제언 : 0\n",
      "중국의 공세적 외교정책 강화와 한중관계의 미래 : 0\n",
      "온기를 잃어버린 사회, 전환적 공정 담론이 필요하다 : 0\n",
      "교육, 교육 그리고 교육 : 0\n",
      "지속가능한 국정 미래설계 체계를 구축하자 : 0\n",
      "교육불평등 시대 우리 아이들 : 0\n",
      "인구 감소와 공교육 보릿고개를 넘어서 : 0\n",
      "문화예술 강국에서 문화예술 선진국으로 : 0\n",
      "신뢰자본 구축이 대한민국을 위한 최고의 투자 : 0\n",
      "한국 정치가 마주하고 있는 변화와 미래 : 0\n",
      "국회미래연구원 춘계 학술대회를 보며 : 0\n",
      "어벤져스'에서 읽어보는 미래와 산업혁명에 대한 기대 : 0\n",
      "총선이 끝나고 : 젊은이들의 선택과 미래를 위한 단상 : 0\n",
      "기본소득이 풍요로운 미래에는 사회보장의 대안이 될 수 있을까? : 0\n",
      "메타버스 시대, 한류를 넘어 문화강국으로 도약해야 : 0\n",
      "인구 절벽, 그 사이 심화되는‘지방 소멸’, 조속히 정책 컨센서스 이뤄야 : 0\n",
      "아버지의직업 : 0\n",
      "왜 미래학인가? : 0\n",
      "인공지능 시대와 사람중심 정치 : 0\n",
      "국회 개혁을 통해 국민 신뢰를 회복하자 : 0\n",
      "도시의 노후 인프라를 체계적으로 관리하자! : 0\n",
      "대한민국 에너지 산업의 미래, 인재육성에 달렸다 : 0\n",
      "지속 가능한 대한민국의 미래 : 0\n",
      "미래의 대한민국, 어떤 인재가 필요한가 : 0\n",
      "지나간 미래의 안전과 다가올 과거의 위험 : 0\n",
      "확정적 미래, 초고령 사회의 도전에 대한 응전이 시급하다 : 0\n",
      "바이든 대통령 집권과 미중 패권경쟁의 미래 : 0\n",
      "농업과 토지이용의 변혁, 탄소중립 달성의 가능성을 높인다 : 0\n",
      "대한민국 위기의 근저에는 정치의 위기가 있다 : 0\n",
      "간호법 제정은 미래를 위한 준비 : 0\n",
      "기후위기와 정의로운 전환 : 0\n",
      "포스트 코로나 시대의 정치 : 0\n",
      "스타트업 정신에서 찾는 정치의 미래 : 0\n",
      "규제개혁 없이는 대한민국의 미래도 없다 : 0\n",
      "인간과 로봇이 공존하는 미래 대한민국 : 0\n",
      "지속 가능한 고등교육의 미래와 대학의 역할 : 0\n",
      "국회, 지난 70년 총정리가 필요하다. : 0\n",
      "10년안에 세계 1등 국가 만들자 : 0\n",
      "인도, 아프리카, 멕시코 미래연구를 통해 배운 점 : 0\n",
      "전염병의 파괴력과 다자주의의 위기 : 0\n",
      "4차 산업혁명·기술혁신 시대의 시민 덕목 : 0\n",
      "기후정의와 불평등 해소 위한 주4일제 사회혁신 : 0\n",
      "저출산·고령화 문제 직면 대한민국…인구정책 대전환 필요 : 0\n",
      "소멸위기의 지방, 대한민국의 미래는? : 0\n",
      "과학기술강국으로의 길 : 0\n",
      "문화·예술·체육·관광분야가 주도해야 할 4차산업혁명 : 0\n",
      "특명! 뭉이와 뭉글이를 보호하라! : 0\n",
      "저작권에 대한 올바른 이해만이 우리 청소년들을 지킬 수 있다. : 0\n",
      "이공계 연구직의 현재와 미래 : 0\n",
      "상처 난 인간의 자존심 : 0\n",
      "미래의 가치를 향하여 : 0\n",
      "코로나 이후, 완전한 디지털 사회! : 0\n",
      "코로나19 시대에 생각하는 행복과 삶의 질 : 0\n",
      "4차 산업혁명 시대의 국토 : 0\n",
      "개인이 미래다! : 0\n",
      "신뢰는 받는 게 아니라 주는 것이다 : 0\n",
      "메타버스와 포용도시…우리는 어떤 미래사회 만들어야 할까 : 0\n",
      "실패해도 괜찮아' 지속 가능한 청년문화예술을 위해 : 0\n",
      "인공지능 시대의 정책 과제 : 0\n",
      "국가의 밝은 미래는 건강한 '가정'을 통해서만 가능하다 : 0\n",
      "함께하는 우리 교육의 미래 : 0\n",
      "시험 성적은 좋았지만 : 0\n",
      "에스키모의 여름 살림 : 0\n",
      "4차 산업혁명의 빛과 그림자 : 0\n",
      "한국형 혁신성장의 고유한 비전 - ABC KOREA : 0\n",
      "존엄하고 아름답게 삶을 마무리 하는 문화가 필요하다 : 0\n",
      "국회는 새 시대 담을 새 그릇 준비해야 : 0\n",
      "미래를 위하여 '제대로' 확인해야 할 현재 : 0\n",
      "미래 산업경쟁력과 혁신의 중요성 : 0\n",
      "국제환경분쟁과 미래 : 0\n",
      "중국몽이 완성되는 2050년 중국의 미래는 : 0\n",
      "교육과 빅데이터 : 0\n",
      "대한민국 시민사회, 그 위대함에 대하여 : 0\n",
      "국제 제도 플랫폼의 미래 : 0\n",
      "2022년 1월 미래 시나리오 : 0\n",
      "코로나 슬라이드와 교육 당국의 역량 : 0\n",
      "전환시대의 공공계획 : 0\n",
      "미래는 위험거버넌스에 달려 있다 -국회미래연구원의 미래임무- : 0\n",
      "사라진 미래과제 0순위, 공적연금 재정안정화 개혁 : 0\n",
      "대전환의 시대, 꿈을 꾸는 미래전략이 필요하다 : 0\n",
      "한국 경제의 신화적 성장에 가려진 불평등과 미래 과제 : 0\n",
      "국가균형발전은 절체절명의 과제다 : 0\n",
      "디지털 대전환 시대의 소상공인 : 0\n",
      "미래복합재난에 대한 진단과 대응 : 0\n",
      "나는 쓰고 있다. 고로 저작권을 가진다. : 0\n",
      "미래를 대처해 나가는 지혜 : 0\n",
      "우리의 미래는 우리의 손으로 결정하는 것입니다 : 0\n",
      "북핵 해법, '뉴딜'로 가야 : 0\n",
      "인도 '기술비전 2047'을 통해 본 과학기술정책의 시사점 : 0\n",
      "노회찬의 미래공부 습관 : 0\n",
      "미래, 인간은 퇴장할 것인가 : 0\n",
      "기후 위기 대응책으로서 철도교통 : 0\n",
      "대한민국의 미래는 외교가 결정한다 : 0\n",
      "우리 아빠가 실업자가 된다고 : 0\n",
      "에스키모의 겨울 살림 : 0\n",
      "남극을 탐험한 사람들 : 0\n",
      "알프스에서 : 0\n",
      "우리의 민족성 : 0\n",
      "노벨과 노벨상 : 0\n",
      "혁신, 사회적 대타협 없이는 불가능하다 : 0\n",
      "유럽과 아프리카 미래비전 연구를 통해 본 한국사회 미래연구의 의의와 역할 : 0\n",
      "한국 청년 정치의 미래를 위한 제언 : 0\n",
      "\"루비콘 강을 건너다\" : 0\n",
      "기본소득토지세와 주택문제 : 0\n",
      "한 마리 나비의 소중한 날갯짓 : 0\n",
      "살려는 노력 : 0\n",
      "에스키모의 집 : 0\n",
      "땅고르기 방법에는 어떤 것이 있는가? : 0\n",
      "꾸준한 희생 : 0\n",
      "면양 : 0\n",
      "한국사회의 현재와 4차 산업혁명의 미래사회 : 0\n",
      "미래의 지속가능한 안전: 자유로운 정보와 민간의 창발이 열쇠 : 0\n",
      "저작이의저작권일기 : 0\n",
      "8_마지막 밤 : 0\n",
      "공중 도덕의 의의와 필요성 : 0\n",
      "생활과 근로정신 : 0\n",
      "신용의 뜻과 성공의 기초 : 0\n",
      "관용과 화합 : 0\n",
      "책임의 완수 : 0\n",
      "개인의 도덕적 자각 : 0\n",
      "문장법과 문장도 : 0\n",
      "자랑스러운 우리글 : 0\n",
      "사하라 사막 : 0\n",
      "사하라에 사는 사람 : 0\n",
      "오아시스 : 0\n",
      "지구는 둥글다 : 0\n",
      "지도 공부 : 0\n",
      "볏짚을 가지고 무엇을 만드는가? : 0\n",
      "삼국의 건국 : 0\n",
      "우리몸의 생김새는 어떻게 되어 있는가 : 0\n",
      "가정 : 0\n",
      "개미의 자랑 : 0\n",
      "우리나라 : 0\n",
      "평화와 유엔 : 0\n",
      "자연을 이용하는 노력 : 0\n",
      "자연의 모습 : 0\n",
      "교통의 시작과 발전 : 0\n",
      "스마트 시티가 그리는 미래 : 0\n",
      "늙는노래 : 0\n",
      "풍습과 그 개선 : 0\n",
      "생활의 안정과 가정 : 0\n",
      "형제 자매와 친척 : 0\n",
      "부부의 도리 : 0\n",
      "옛날의 효도와 본 뜻 : 0\n",
      "학교에서 지켜야할 도덕 : 0\n",
      "공동생활과 자기 지위 : 0\n",
      "노동의 신성 : 0\n",
      "협동정신과 각 개인의 사회적 관련 : 0\n",
      "야구의 성격 : 0\n",
      "꽃을 나누어 보면 : 0\n",
      "양심의 의의와 그 작용 : 0\n",
      "인권의 본질과 사람의 권리 : 0\n",
      "물건의 가치와 정신적 가치 : 0\n",
      "인간 본성의 양면 : 0\n",
      "참된 인생의 길을 찾아서 : 0\n",
      "동기와 결과의 관계 : 0\n",
      "인격의 본질 : 0\n",
      "고운 음성과 바른 말 : 0\n",
      "말의 아름다움 : 0\n",
      "성명의 의미 : 0\n",
      "제비 : 0\n",
      "기압 : 0\n",
      "씨앗은 어떻게 해서 생기는가? : 0\n",
      "버섯 : 0\n",
      "지구 위의 바다와 육지 : 0\n",
      "목축업 : 0\n",
      "황산암모니아 쓰는 법 : 0\n",
      "우리 집에서는 밭과 논에 무슨 농작물을 심는가? : 0\n",
      "콩은 어떻게 심는가? : 0\n",
      "거름과 농작물의 관계는 어떠한가? : 0\n",
      "꽃은 어떻게 가꾸는가? : 0\n",
      "묘포라는 것은 무엇인가? : 0\n",
      "닭은 어떻게 기르면 좋은가? : 0\n",
      "좋은 씨앗이란 어떠한 것인가? : 0\n",
      "흙은 어떻게하여 되었는가? : 0\n",
      "우리 민족의 이루어짐과 옛 살림 : 0\n",
      "옛 사회가 발전하여 나라를 이루게 되는 모양과 고조선 밖의 상고의 여러 나라에 관하여 : 0\n",
      "미신과과학 : 0\n",
      "지구 표면의 변화는 지구가 오래되었다는 것을 어떻게 말하고 있는가? : 0\n",
      "왜 사람들은 모여서 살까 : 0\n",
      "꿀통안에는 몇가지 벌이 있을까 : 0\n",
      "조그만 일이라도 : 0\n",
      "별나라 : 0\n",
      "우리들의 약속 : 0\n",
      "죽음의 바다 : 0\n",
      "가도가도 끝 없는 모래나라 : 0\n",
      "세계에서 제일 추운 얼음나라 : 0\n",
      "법의 목적 : 0\n",
      "두 가지 사상에 대한 비판 : 0\n",
      "참된 인생과 값이 있는 인생 : 0\n",
      "거미 : 0\n",
      "바람 : 0\n",
      "구름 : 0\n",
      "곰팡이 : 0\n",
      "달걀 : 0\n",
      "남극 대륙 : 0\n",
      "임업 : 0\n",
      "광업 : 0\n",
      "우리가 먹고 있는 과실에는 몇가지의 종류가 있는가? : 0\n",
      "콩깨묵은 무엇인가 : 0\n",
      "화학거름은 무슨 거름인가? : 0\n",
      "화단은 우리 생활과 어떠한 관계가 있는가? : 0\n",
      "옛 사람들의 사회와 그 생활 : 0\n",
      "신라 통일기의 문화 : 0\n",
      "고려의 사회와 문화 : 0\n",
      "미신타파 : 0\n",
      "오락의 필요성 : 0\n",
      "공동 생활과 정치 : 0\n",
      "우리는 왜 물을 보존해야하는가? : 0\n",
      "동물의 화석을보고 어떻게 지구의 나이를 알 수 있는가? : 0\n",
      "지구가 얼마나 오래 되었나 하는 것을 어떻게 아는가 : 0\n",
      "어떻게하면 몸이 잘 일하게 할 수 있을까 : 0\n",
      "벌이나 개미의 사회와 사람의 사회와 다른 점은 무엇인가 : 0\n",
      "물총새 : 0\n",
      "오리 : 0\n"
     ]
    }
   ],
   "source": [
    "for tt, count in count:\n",
    "    correct = [i for i in train_df[\"title\"] if i == tt]\n",
    "    print(f\"{tt} : {len(correct)}\")\n",
    "\n",
    "# title 겹치는건 하나도 없다 --> cosine embedding similiar 로 접근해야 하네 ( RAG )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문체 혼용 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def split_sentences(text):\n",
    "    return re.split(r'(?<=[.?!])\\s+', text.strip())\n",
    "\n",
    "def classify_style(sentence):\n",
    "    sentence = sentence.strip()\n",
    "\n",
    "    if re.search(r'니다\\.$', sentence):\n",
    "        return \"습니다체\"\n",
    "    elif re.search(r'다\\.$', sentence):\n",
    "        return \"이다체\"\n",
    "    else:\n",
    "        return \"기타\"\n",
    "\n",
    "def analyze_paragraph_style(paragraph):\n",
    "    sentences = split_sentences(paragraph)\n",
    "    labeled = [(s, classify_style(s)) for s in sentences if s]\n",
    "\n",
    "    # '기타' 제외하고 혼용 여부 판단\n",
    "    styles_used = {style for _, style in labeled if style in {\"습니다체\", \"이다체\"}}\n",
    "    mixed = len(styles_used) > 1\n",
    "\n",
    "    return mixed, labeled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/89177 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 89177/89177 [00:03<00:00, 22814.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "혼용 개수 7366 비율 : 0.08259977348419435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "label_0_mix = []\n",
    "\n",
    "for i in tqdm(label_0, total=len(label_0)):\n",
    "    paragraph = i['full_text']\n",
    "    mixed, labeled = analyze_paragraph_style(paragraph)\n",
    "    label_0_mix.append(mixed)\n",
    "\n",
    "print(f\"혼용 개수 {sum(label_0_mix)} 비율 : {sum(label_0_mix)/len(label_0_mix)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7995/7995 [00:00<00:00, 22484.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "혼용 개수 5489 비율 : 0.6865540963101938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "label_1_mix = []\n",
    "\n",
    "for i in tqdm(label_1, total=len(label_1)):\n",
    "    paragraph = i['full_text']\n",
    "    mixed, labeled = analyze_paragraph_style(paragraph)\n",
    "    label_1_mix.append(mixed)\n",
    "\n",
    "print(f\"혼용 개수 {sum(label_1_mix)} 비율 : {sum(label_1_mix)/len(label_1_mix)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>full_text</th>\n",
       "      <th>paragraph_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"루비콘 강을 건너다\"</td>\n",
       "      <td>루비콘 강은 이탈리아 북부에 위치한 작은 강으로 되돌아 갈 수 없는 상황에 처해 있...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.10%</td>\n",
       "      <td>토렌트 다운 중 0.3% 밤 11시. 늦은 밤, 집에 돌아온 나는 자연스럽게 컴퓨터...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10년안에 세계 1등 국가 만들자</td>\n",
       "      <td>금년이 3.1운동 100주년입니다. 이 뜻깊은 해를 맞아 특별히 강조하고 싶은 점이...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022년 1월 미래 시나리오</td>\n",
       "      <td>2020년 1월 코로나가 확산되기 시작했을 때, 무려 1년반이 넘도록 지금 이 시간...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4차 산업혁명 시대의 국토</td>\n",
       "      <td>과거 보통 사람들의 희망은 살 집과 농사지을 땅을 마련하는 것이었고 국토가 그 희망...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                title                                          full_text  \\\n",
       "0        \"루비콘 강을 건너다\"  루비콘 강은 이탈리아 북부에 위치한 작은 강으로 되돌아 갈 수 없는 상황에 처해 있...   \n",
       "1               0.10%  토렌트 다운 중 0.3% 밤 11시. 늦은 밤, 집에 돌아온 나는 자연스럽게 컴퓨터...   \n",
       "2  10년안에 세계 1등 국가 만들자  금년이 3.1운동 100주년입니다. 이 뜻깊은 해를 맞아 특별히 강조하고 싶은 점이...   \n",
       "3    2022년 1월 미래 시나리오  2020년 1월 코로나가 확산되기 시작했을 때, 무려 1년반이 넘도록 지금 이 시간...   \n",
       "4      4차 산업혁명 시대의 국토  과거 보통 사람들의 희망은 살 집과 농사지을 땅을 마련하는 것이었고 국토가 그 희망...   \n",
       "\n",
       "   paragraph_count  \n",
       "0                6  \n",
       "1               16  \n",
       "2               10  \n",
       "3                8  \n",
       "4                9  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### test 데이터 합치기\n",
    "\n",
    "test_csv = test_df.rename(columns={'paragraph_text': 'full_text'})\n",
    "# 그룹핑하고 문단 순서대로 이어 붙이기\n",
    "grouped = (\n",
    "    test_csv\n",
    "    .sort_values(by=[\"title\", \"paragraph_index\"])\n",
    "    .groupby(\"title\")\n",
    "    .agg({\n",
    "        \"full_text\": lambda x: \"\\n\\n\".join(x),\n",
    "        \"paragraph_index\": \"count\"  # 문단 개수 세기\n",
    "    })\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# 컬럼 이름 변경\n",
    "grouped = grouped.rename(columns={\n",
    "    \"paragraph_index\": \"paragraph_count\"\n",
    "})\n",
    "\n",
    "grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 253/253 [00:00<00:00, 17110.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "혼용 개수 82 비율 : 0.3241106719367589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "label_test_mix = []\n",
    "\n",
    "test = [i for _,i in grouped.iterrows()]\n",
    "\n",
    "for i in tqdm(test, total=len(test)):\n",
    "    paragraph = i['full_text']\n",
    "    mixed, labeled = analyze_paragraph_style(paragraph)\n",
    "    label_test_mix.append(mixed)\n",
    "\n",
    "print(f\"혼용 개수 {sum(label_test_mix)} 비율 : {sum(label_test_mix)/len(label_test_mix)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 545/1962 [00:00<00:00, 5443.74it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (538 > 512). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 1962/1962 [00:00<00:00, 5248.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "잘린다고 예상되는 샘플 수: 3 / 전체 1962개 중 0.15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('klue/roberta-large')\n",
    "\n",
    "cut = 0\n",
    "test_df = test_df.rename(columns={'paragraph_text': 'full_text'})\n",
    "for _, row in tqdm(test_df.iterrows(), total=len(test_df)):\n",
    "    text = row['full_text']\n",
    "    output = tokenizer(\n",
    "        text,\n",
    "        truncation=False,            # ✅ 자르지 않음\n",
    "        padding=False,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    if output['input_ids'].shape[1] > 512:\n",
    "        cut += 1\n",
    "\n",
    "print(f\"잘린다고 예상되는 샘플 수: {cut} / 전체 {len(test_df)}개 중 {cut / len(test_df) * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 문서(title) 단위로 문단 합치기\n",
    "grouped = test_df.groupby(\"title\")[\"paragraph_text\"].apply(lambda x: \" \".join(x)).reset_index()\n",
    "\n",
    "# 3. 각 문서에 대해 혼용 여부 판단\n",
    "grouped[\"is_mixed\"] = grouped[\"paragraph_text\"].apply(lambda x: int(analyze_paragraph_style(x)[0]))\n",
    "\n",
    "\n",
    "# 4. 다시 원래 데이터에 혼용 여부 병합 (모든 문단에 동일 라벨)\n",
    "df = test_df.merge(grouped[[\"title\", \"is_mixed\"]], on=\"title\", how=\"left\")\n",
    "\n",
    "\n",
    "sample_submission = pd.read_csv(f\"{data_base}/sample_submission.csv\", encoding='utf-8-sig')\n",
    "all_AI = [i['is_mixed'] for _,i in df.iterrows()]\n",
    "sample_submission['generated'] = all_AI\n",
    "\n",
    "sample_submission.to_csv(f\"{data_base}/문체분석.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 개수 1109 1 개수 853\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(f\"{data_base}/문체분석.csv\")\n",
    "\n",
    "df_0 = [i for _, i in df.iterrows() if i['generated'] == 0]\n",
    "df_1 = [i for _, i in df.iterrows() if i['generated'] == 1]\n",
    "\n",
    "print(f\"0 개수 {len(df_0)} 1 개수 {len(df_1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "카호올라웨섬은 하와이 제도를 구성하는 8개의 화산섬 가운데 하나로 면적은 115.5km2, 높이는 452m이다. 하와이 제도에서 가장 작은 화산섬이자 무인도이며 길이는 18km, 너비는 10km이다. \n",
      " 마우이섬에서 남서쪽으로 약 11km 정도 떨어진 곳에 위치하며 라나이섬의 남동쪽에 위치한다. 고도가 낮고 북동쪽에서 불어오는 무역풍을 통해 산악 지대에서 내리는 비를 형성하지 못하기 때문에 건조한 기후를 띤다. 마우이섬 화산의 비그늘에 속해 있기 때문에 섬 전체 면적의 1/4 이상이 부식되어 있다. \n",
      " 1000년경부터 사람이 거주했으며 해안 지대에는 소규모 임시 어촌이 형성되었다. 섬 안에는 주민들이 돌로 만든 제단에서 종교 의식을 거행한 흔적들, 주민들이 암석이나 평평한 돌에 그림을 그린 흔적들이 남아 있다. 1778년부터 1800년대까지 이 지역을 지나 항해하던 사람들의 보고에 따르면 카호올라웨섬은 무인도였고 나무도 물도 없는 불모지였다고 한다. \n",
      " 1830년대에는 하와이 왕국의 카메하메하 3세 국왕에 의해 남자 죄수들의 유형지로 사용되었지만 1853년에 폐지되었다. 1858년에는 하와이 정부가 목장 사업가들에게 카호올라웨섬을 양도했지만 가뭄과 과도한 방목으로 인해 땅이 말라갔다. 또한 강한 무역풍으로 인해 표토의 대부분이 날아가면서 붉은 경반층만 남게 되었다. \n",
      " 1910년부터 1918년까지 하와이 준주가 섬의 원래 모습을 복원하기 위해 이 섬을 천연보호구역으로 지정했지만 큰 성과를 거두지 못했다. \n",
      " 1941년 12월 7일에 일어난 일본 제국 해군의 진주만 공격을 계기로 카호올라웨섬은 태평양 전쟁에 참전한 미국 병사들의 훈련소로 사용되었다. 1981년 3월 18일에는 미국 국립사적지에 등재되었다.\n"
     ]
    }
   ],
   "source": [
    "label_0\n",
    "label_1\n",
    "test = test_df[\"paragraph_text\"]\n",
    "\n",
    "print(label_0[0][\"full_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "수난곡(受難曲)은 배우의 연기 없이 무대에 올려지는 성악을 주로 한 종합 예술이다. 이러한 의미에서 오라토리오와 유사하지만, 성경의 사복음서를 기반으로 한 예수 그리스도의 생애를 주로 다루고 있다는 점에서 차이가 있다. 또한 이는 주로 독일 계열 작곡가들에게 쓰인 개념이다. 수난 또는 수난곡을 뜻하는 영어 'Passion'은 2세기에 나타난 라틴어 \"passio\"에서 유래하며, 예수의 생애와 고난이란 의미를 담고 있다.\n",
      "사복음서에 기록된 예수님의 수난 이야기는 마태오, 마르코, 루카, 요한 복음서에 각각 담겨 있습니다. 이를 바탕으로 '마태오 수난곡', '마르코 수난곡', '루카 수난곡', '요한 수난곡'이라는 4개의 작품이 만들어졌죠. 이들 작품은 예수님의 고난과 십자가 처형을 다루고 있습니다.\n",
      "옛날부터 성(聖) 금요일이나 성주간(聖週間)에는 수난극이나 이와 비슷한 행사를 하였다. 12세기경부터 복음서에 따라 그리스도 수난의 이야기를 3인의 신부가, 한 사람은 복음사가(福音史家)의 역(테너)을, 또 한 사람은 그리스도의 역(베이스)을, 나머지 한 사람은 군중의 역(알토)을 맡아 낭독조로 노래하는 습관이 되었다. 이것이 그 뒤의 수난곡의 기원이다. 이와 같은 형식으로 된 수난곡을 '코랄 수난곡'이라 하며, 대략 17세기경까지 만들어졌다. 특히 유명한 작품으로는 쉬츠의 《마태오 수난곡》이 있다. 이와 함께 16세기-17세기에는 다른 타입의 '모테토 수난곡'이 생겼다. 이것은 텍스트의 전체를 등장인물의 수와 관계없이 일관하여 모테토풍의 다성부 합창으로 노래한다. 음악사적으로 가장 중요한 것은 17세기 중엽경에 성립한 '오라토리오 수난곡'이다. 이것은 일반적으로 성서의 텍스트를 자유롭게 시로 만들어 코랄 또는 솔로의 아리아 형식으로 삽입되어 있기 때문에, 형식적으로도 아리아, 레치타티보, 합창, 통주저음, 기악반주를 썼으며, 오라토리오의 형태와 흡사하다. 이 장르의 대표적 작품으로는 바흐의 《요한 수난곡》과 고금 최대의 걸작이라고 칭찬받고 있는 《마태오 수난곡》이 있다.\n"
     ]
    }
   ],
   "source": [
    "print(label_1[0][\"full_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "나아가 우리가 알아두어야 할 것은 가정 생활이란 자기 한 가정만으로써 행복을 누리는 것이 아니라, 다른 가정과 더불어 국가와 긴밀한 관계에서 이루어진다는 점이다. 사람이란 원래 사회적 동물로서 개인이 홀로 살아갈 수 없기 때문이다. 행복한 가정은 국가발전에 기초가 되며, 건전한 가정은 국가의 보호를 받는다. 오늘날 자녀들은 부모의 자녀로서 가정에 국한된 사람이 아니라, 나라의 자녀들 이라는 것을 알아야한다. 국가는 가정 내부에 대해 공연한 간섭을 하지 않고 가정의 자립을 보장하지만, 가정 안에서 인권을 훼손하는 일이 있을 때는 국가에 의해 제재를 받을 수도 있는 것이다.\n"
     ]
    }
   ],
   "source": [
    "print(test[9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 확률 보정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/aicontest/aicon_2025/data/original/roberta_submission_0.89131.csv\")\n",
    "\n",
    "df['generated'] = np.where(df['generated'] >= 0.99, 1,\n",
    "                  np.where(df['generated'] <= 0.01, 0, df['generated']))\n",
    "\n",
    "df.to_csv(\"/home/aicontest/aicon_2025/data/original/roberta_submission_0.89131_확률보정.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 논문 feature 확인 --> train label 별 데이터 위주로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-03 13:13:24.533411: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-03 13:13:24.541344: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1751516004.549829  200487 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1751516004.552057  200487 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-07-03 13:13:24.560346: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Label 0: 100%|██████████| 89177/89177 [21:12<00:00, 70.10it/s]\n",
      "Label 1: 100%|██████████| 7995/7995 [01:47<00:00, 74.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: Human | Avg PPL: 7.96\n",
      "Label: AI | Avg PPL: 7.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Perplexity 확인\n",
    "\n",
    "model_name = \"gpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "model.eval().to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Perplexity 계산 함수\n",
    "def calculate_perplexity(text, model, tokenizer, device=\"cpu\"):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "    input_ids = inputs[\"input_ids\"].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, labels=input_ids)\n",
    "        loss = outputs.loss\n",
    "        ppl = torch.exp(loss).item()\n",
    "    return ppl\n",
    "\n",
    "label_ppl = {}\n",
    "\n",
    "human_ppls = []\n",
    "for text in tqdm(label_0, desc=f\"Label 0\"):\n",
    "    ppl = calculate_perplexity(text[\"full_text\"], model, tokenizer, device=model.device)\n",
    "    human_ppls.append(ppl)\n",
    "label_ppl[\"Human\"] = sum(human_ppls) / len(human_ppls) if human_ppls else float('inf')\n",
    "\n",
    "AI_ppls = []\n",
    "for text in tqdm(label_1, desc=f\"Label 1\"):\n",
    "    ppl = calculate_perplexity(text[\"full_text\"], model, tokenizer, device=model.device)\n",
    "    AI_ppls.append(ppl)\n",
    "label_ppl[\"AI\"] = sum(AI_ppls) / len(AI_ppls) if AI_ppls else float('inf')\n",
    "\n",
    "# 결과 출력\n",
    "for label, ppl in label_ppl.items():\n",
    "    print(f\"Label: {label} | Avg PPL: {ppl:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 0 | Avg Subjectivity: 0.033\n",
      "Label: 1 | Avg Subjectivity: 0.027\n"
     ]
    }
   ],
   "source": [
    "## subjectivity and objectivity\n",
    "## 0에 가까울수록 객관적\n",
    "## 1에 가까울수록 주관적\n",
    "\n",
    "def get_subjectivity_score(text):\n",
    "    if not isinstance(text, str):\n",
    "        return 0.0\n",
    "    return TextBlob(text).sentiment.subjectivity\n",
    "\n",
    "# label_0 처리\n",
    "label_0_df = pd.DataFrame(label_0)\n",
    "label_0_df[\"label\"] = 0\n",
    "label_0_df[\"subjectivity\"] = label_0_df[\"full_text\"].apply(get_subjectivity_score)\n",
    "\n",
    "# label_1 처리\n",
    "label_1_df = pd.DataFrame(label_1)\n",
    "label_1_df[\"label\"] = 1\n",
    "label_1_df[\"subjectivity\"] = label_1_df[\"full_text\"].apply(get_subjectivity_score)\n",
    "\n",
    "# 합치기\n",
    "combined_df = pd.concat([label_0_df, label_1_df], ignore_index=True)\n",
    "\n",
    "# label별 평균 subjectivity 계산\n",
    "label_subjectivity = combined_df.groupby(\"label\")[\"subjectivity\"].mean().to_dict()\n",
    "\n",
    "# 출력\n",
    "for label, score in label_subjectivity.items():\n",
    "    print(f\"Label: {label} | Avg Subjectivity: {score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불용어 개수 : 675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 89177/89177 [1:31:10<00:00, 16.30it/s]  \n",
      "100%|██████████| 7995/7995 [08:21<00:00, 15.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불용어 개수 label 0 : 19180068\n",
      "불용어 개수 label 1 : 1671692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## stop word\n",
    "# tqdm 설정\n",
    "tqdm.pandas()\n",
    "\n",
    "# 불용어 리스트 불러오기\n",
    "stop_words_list = stopwords.words('/home/aicontest/nltk_data/corpora/stopwords/korean')\n",
    "print('불용어 개수 :', len(stop_words_list))\n",
    "\n",
    "# 형태소 분석기\n",
    "okt = Okt()\n",
    "\n",
    "# 불용어 개수 세기 함수\n",
    "def count_korean_stopwords(text):\n",
    "    if not isinstance(text, str):\n",
    "        return 0\n",
    "    tokens = okt.morphs(text)\n",
    "    return sum(1 for token in tokens if token in stop_words_list)\n",
    "\n",
    "# tqdm 적용한 불용어 개수 세기\n",
    "label_0_df['stopword_count'] = label_0_df['full_text'].progress_apply(count_korean_stopwords)\n",
    "label_1_df['stopword_count'] = label_1_df['full_text'].progress_apply(count_korean_stopwords)\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"불용어 개수 label 0 : {sum(label_0_df['stopword_count'])}\")\n",
    "print(f\"불용어 개수 label 1 : {sum(label_1_df['stopword_count'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불용어 평균 label 0 : 215.07864135371227\n",
      "불용어 평균 label 1 : 209.09218261413383\n"
     ]
    }
   ],
   "source": [
    "print(f\"불용어 평균 label 0 : {sum(label_0_df['stopword_count'])/len(label_0_df)}\")\n",
    "print(f\"불용어 평균 label 1 : {sum(label_1_df['stopword_count'])/len(label_1_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 89177/89177 [00:00<00:00, 140473.19it/s]\n",
      "100%|██████████| 7995/7995 [00:00<00:00, 140156.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 0 total quotations: 701986\n",
      "Label 1 total quotations: 56898\n",
      "Label 0 avg quotations: 7.87182793769694\n",
      "Label 1 avg quotations: 7.116697936210131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## quotation 측정\n",
    "\n",
    "def count_quotation_marks(text):\n",
    "    if not isinstance(text, str):\n",
    "        return 0\n",
    "\n",
    "    # 다양한 종류의 인용부호 포함\n",
    "    quotation_marks = [\n",
    "        '\"', \"'\",         # 일반 쌍따옴표, 홑따옴표\n",
    "        '“', '”',         # 유니코드 쌍따옴표\n",
    "        '‘', '’',         # 유니코드 홑따옴표\n",
    "        '„', '‟', '‹', '›', '«', '»'  # 기타 유럽권 인용부호\n",
    "    ]\n",
    "\n",
    "    return sum(text.count(mark) for mark in quotation_marks)\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "# 컬럼에 적용\n",
    "label_0_df['quotation_count'] = label_0_df['full_text'].progress_apply(count_quotation_marks)\n",
    "label_1_df['quotation_count'] = label_1_df['full_text'].progress_apply(count_quotation_marks)\n",
    "\n",
    "# 요약 출력\n",
    "print(f\"Label 0 total quotations: {label_0_df['quotation_count'].sum()}\")\n",
    "print(f\"Label 1 total quotations: {label_1_df['quotation_count'].sum()}\")\n",
    "print(f\"Label 0 avg quotations: {label_0_df['quotation_count'].sum()/len(label_0_df)}\")\n",
    "print(f\"Label 1 avg quotations: {label_1_df['quotation_count'].sum()/len(label_1_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 89177/89177 [00:00<00:00, 1344788.53it/s]\n",
      "100%|██████████| 7995/7995 [00:00<00:00, 77191.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing text: 그는 왕족이었고, 특히 그의 친가는 겹사돈으로 유명한 ... -> 'result'\n",
      "Error processing text: 일본 하리마 국(播磨国) 출신이다.\n",
      "쇼샤 산에서 천태교... -> 'result'\n",
      "Error processing text: 리본은 히트맨이자 주인공인 츠나의 가정교사다. 그는 검... -> 'result'\n",
      "Label 0 맞춤법 오류 총합: 0\n",
      "Label 1 맞춤법 오류 총합: 0\n",
      "Label 0 맞춤법 오류 평균: 0.0\n",
      "Label 1 맞춤법 오류 평균: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## 맞춤법\n",
    "\n",
    "def count_spelling_errors(text):\n",
    "    try:\n",
    "        result = spell_checker.check(text)\n",
    "        return result.errors  # 맞춤법 오류 개수 반환\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing text: {text[:30]}... -> {e}\")\n",
    "        return 0\n",
    "    \n",
    "tqdm.pandas()\n",
    "\n",
    "label_0_df['spelling_error_count'] = label_0_df['full_text'].progress_apply(count_spelling_errors)\n",
    "label_1_df['spelling_error_count'] = label_1_df['full_text'].progress_apply(count_spelling_errors)\n",
    "\n",
    "print(f\"Label 0 맞춤법 오류 총합: {label_0_df['spelling_error_count'].sum()}\")\n",
    "print(f\"Label 1 맞춤법 오류 총합: {label_1_df['spelling_error_count'].sum()}\")\n",
    "print(f\"Label 0 맞춤법 오류 평균: {label_0_df['spelling_error_count'].sum()/len(label_0_df)}\")\n",
    "print(f\"Label 1 맞춤법 오류 평균: {label_1_df['spelling_error_count'].sum()/len(label_1_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 89177/89177 [57:06<00:00, 26.03it/s]  \n",
      "100%|██████████| 7995/7995 [05:05<00:00, 26.21it/s]\n"
     ]
    }
   ],
   "source": [
    "## readability\n",
    "label_0_df = pd.read_csv(\"./label_0_EDA.csv\")\n",
    "label_1_df = pd.read_csv(\"./label_1_EDA.csv\")\n",
    "\n",
    "okt = Okt()\n",
    "\n",
    "def get_korean_readability(text):\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return {\n",
    "            \"avg_sentence_length\": 0,\n",
    "            \"avg_word_length\": 0,\n",
    "            \"num_sentences\": 0,\n",
    "            \"num_words\": 0,\n",
    "        }\n",
    "\n",
    "    # 문장 분리 (간단히 마침표 기준)\n",
    "    sentences = re.split(r'[.!?。!?]', text)\n",
    "    sentences = [s.strip() for s in sentences if s.strip()]\n",
    "    \n",
    "    # 어절 분리\n",
    "    words = text.split()\n",
    "    morphs = okt.morphs(text)\n",
    "\n",
    "    num_sentences = len(sentences)\n",
    "    num_words = len(words)\n",
    "    num_morphs = len(morphs)\n",
    "    total_chars = sum(len(s) for s in sentences)\n",
    "\n",
    "    return {\n",
    "        \"avg_sentence_length\": total_chars / num_sentences if num_sentences else 0,\n",
    "        \"avg_word_length\": total_chars / num_words if num_words else 0,\n",
    "        \"num_sentences\": num_sentences,\n",
    "        \"num_words\": num_words,\n",
    "        \"num_morphs\": num_morphs\n",
    "    }\n",
    "\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "readability_results = label_0_df['full_text'].progress_apply(get_korean_readability)\n",
    "readability_df = pd.DataFrame(readability_results.tolist())\n",
    "\n",
    "# 결과 합치기\n",
    "label_0_df = pd.concat([label_0_df, readability_df], axis=1)\n",
    "\n",
    "readability_results = label_1_df['full_text'].progress_apply(get_korean_readability)\n",
    "readability_df = pd.DataFrame(readability_results.tolist())\n",
    "\n",
    "# 결과 합치기\n",
    "label_1_df = pd.concat([label_1_df, readability_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 평균 가독성 지표 (label_0_df):\n",
      "avg_sentence_length : 65.35\n",
      "avg_word_length     : 4.41\n",
      "num_sentences       : 36.05\n",
      "num_words           : 511.16\n",
      "num_morphs          : 959.69\n",
      "📊 평균 가독성 지표 (label_1_df):\n",
      "avg_sentence_length : 55.69\n",
      "avg_word_length     : 4.33\n",
      "num_sentences       : 40.89\n",
      "num_words           : 515.54\n",
      "num_morphs          : 949.96\n"
     ]
    }
   ],
   "source": [
    "# 측정할 컬럼 목록\n",
    "readability_columns = [\n",
    "    \"avg_sentence_length\",\n",
    "    \"avg_word_length\",\n",
    "    \"num_sentences\",\n",
    "    \"num_words\",\n",
    "    \"num_morphs\"\n",
    "]\n",
    "\n",
    "print(\"📊 평균 가독성 지표 (label_0_df):\")\n",
    "for col in readability_columns:\n",
    "    mean_val = label_0_df[col].mean()\n",
    "    print(f\"{col:<20}: {mean_val:.2f}\")\n",
    "\n",
    "# 측정할 컬럼 목록\n",
    "readability_columns = [\n",
    "    \"avg_sentence_length\",\n",
    "    \"avg_word_length\",\n",
    "    \"num_sentences\",\n",
    "    \"num_words\",\n",
    "    \"num_morphs\"\n",
    "]\n",
    "\n",
    "print(\"📊 평균 가독성 지표 (label_1_df):\")\n",
    "for col in readability_columns:\n",
    "    mean_val = label_1_df[col].mean()\n",
    "    print(f\"{col:<20}: {mean_val:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 89177/89177 [00:00<00:00, 831890.52it/s]\n",
      "100%|██████████| 89177/89177 [00:00<00:00, 2480505.66it/s]\n",
      "100%|██████████| 89177/89177 [00:00<00:00, 802472.08it/s]\n",
      "100%|██████████| 89177/89177 [00:04<00:00, 21303.95it/s]\n",
      "100%|██████████| 89177/89177 [00:00<00:00, 241965.41it/s]\n",
      "100%|██████████| 89177/89177 [2:20:25<00:00, 10.58it/s]  \n",
      "100%|██████████| 7995/7995 [00:00<00:00, 819989.25it/s]\n",
      "100%|██████████| 7995/7995 [00:00<00:00, 2388253.01it/s]\n",
      "100%|██████████| 7995/7995 [00:00<00:00, 855729.21it/s]\n",
      "100%|██████████| 7995/7995 [00:00<00:00, 22376.75it/s]\n",
      "100%|██████████| 7995/7995 [00:00<00:00, 290798.77it/s]\n",
      "100%|██████████| 7995/7995 [12:03<00:00, 11.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Summary ===\n",
      "Label 0 total commas: 2225240\n",
      "Label 1 total commas: 132245\n",
      "Label 0 avg commas: 24.9531\n",
      "Label 1 avg commas: 16.5410\n",
      "Label 0 comma inclusion rate: 0.9950\n",
      "Label 1 comma inclusion rate: 0.9800\n",
      "Label 0 avg comma_usage_rate: 0.0111\n",
      "Label 1 avg comma_usage_rate: 0.0072\n",
      "Label 0 avg relative_comma_pos: 0.4789\n",
      "Label 1 avg relative_comma_pos: 0.4742\n",
      "Label 0 avg avg_segment_length: 114.5820\n",
      "Label 1 avg avg_segment_length: 186.9172\n",
      "Label 0 avg pos_diversity_score: 0.4479\n",
      "Label 1 avg pos_diversity_score: 0.4446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "okt = Okt()\n",
    "\n",
    "# CSV 불러오기\n",
    "label_0_df = pd.read_csv(\"/home/aicontest/aicon_2025/analysis/label_0_EDA.csv\")\n",
    "label_1_df = pd.read_csv(\"/home/aicontest/aicon_2025/analysis/label_1_EDA.csv\")\n",
    "\n",
    "# 1. 총 콤마 수\n",
    "def count_commas(text):\n",
    "    if not isinstance(text, str):\n",
    "        return 0\n",
    "    return text.count(',')\n",
    "\n",
    "# 2. 콤마 포함 여부\n",
    "def comma_inclusion(text):\n",
    "    if not isinstance(text, str):\n",
    "        return False\n",
    "    return ',' in text\n",
    "\n",
    "# 3. 콤마 사용 비율\n",
    "def comma_usage_rate(text):\n",
    "    if not isinstance(text, str) or len(text.strip()) == 0:\n",
    "        return 0\n",
    "    return text.count(',') / len(text)\n",
    "\n",
    "# 4. 콤마의 평균 상대 위치\n",
    "def avg_relative_position_of_comma(text):\n",
    "    if not isinstance(text, str) or ',' not in text:\n",
    "        return 0\n",
    "    positions = [i / len(text) for i, c in enumerate(text) if c == ',']\n",
    "    return sum(positions) / len(positions) if positions else 0\n",
    "\n",
    "# 5. 평균 세그먼트 길이 (콤마 기준)\n",
    "def avg_segment_length(text):\n",
    "    if not isinstance(text, str):\n",
    "        return 0\n",
    "    segments = [s.strip() for s in text.split(',')]\n",
    "    lengths = [len(s) for s in segments if s]\n",
    "    return sum(lengths) / len(lengths) if lengths else 0\n",
    "\n",
    "# 6. 콤마 앞뒤 품사 다양성 점수\n",
    "def pos_diversity_score(text):\n",
    "    if not isinstance(text, str) or ',' not in text:\n",
    "        return 0\n",
    "\n",
    "    segments = [s.strip() for s in text.split(',') if s.strip()]\n",
    "    if len(segments) < 2:\n",
    "        return 0\n",
    "\n",
    "    diversity_scores = []\n",
    "    for i in range(len(segments) - 1):\n",
    "        pos_1 = set(pos for _, pos in okt.pos(segments[i]))\n",
    "        pos_2 = set(pos for _, pos in okt.pos(segments[i + 1]))\n",
    "\n",
    "        union = pos_1.union(pos_2)\n",
    "        intersection = pos_1.intersection(pos_2)\n",
    "\n",
    "        score = 1 - len(intersection) / len(union) if union else 0\n",
    "        diversity_scores.append(score)\n",
    "\n",
    "    return sum(diversity_scores) / len(diversity_scores) if diversity_scores else 0\n",
    "\n",
    "\n",
    "# 모든 feature를 DataFrame에 적용\n",
    "def apply_features(df):\n",
    "    df[\"comma_count\"] = df[\"full_text\"].progress_apply(count_commas)\n",
    "    df[\"comma_inclusion\"] = df[\"full_text\"].progress_apply(comma_inclusion)\n",
    "    df[\"comma_usage_rate\"] = df[\"full_text\"].progress_apply(comma_usage_rate)\n",
    "    df[\"relative_comma_pos\"] = df[\"full_text\"].progress_apply(avg_relative_position_of_comma)\n",
    "    df[\"avg_segment_length\"] = df[\"full_text\"].progress_apply(avg_segment_length)\n",
    "    df[\"pos_diversity_score\"] = df[\"full_text\"].progress_apply(pos_diversity_score)\n",
    "    return df\n",
    "\n",
    "label_0_df = apply_features(label_0_df)\n",
    "label_1_df = apply_features(label_1_df)\n",
    "\n",
    "# 요약 출력\n",
    "print(\"=== Summary ===\")\n",
    "print(f\"Label 0 total commas: {label_0_df['comma_count'].sum()}\")\n",
    "print(f\"Label 1 total commas: {label_1_df['comma_count'].sum()}\")\n",
    "\n",
    "print(f\"Label 0 avg commas: {label_0_df['comma_count'].mean():.4f}\")\n",
    "print(f\"Label 1 avg commas: {label_1_df['comma_count'].mean():.4f}\")\n",
    "\n",
    "print(f\"Label 0 comma inclusion rate: {label_0_df['comma_inclusion'].mean():.4f}\")\n",
    "print(f\"Label 1 comma inclusion rate: {label_1_df['comma_inclusion'].mean():.4f}\")\n",
    "\n",
    "for metric in [\"comma_usage_rate\", \"relative_comma_pos\", \"avg_segment_length\", \"pos_diversity_score\"]:\n",
    "    print(f\"Label 0 avg {metric}: {label_0_df[metric].mean():.4f}\")\n",
    "    print(f\"Label 1 avg {metric}: {label_1_df[metric].mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_0_df.to_csv(\"./label_0_EDA.csv\")\n",
    "label_1_df.to_csv(\"./label_1_EDA.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "construct",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
